{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars Eager analysis for banking datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "https://www.kaggle.com/datasets/ismetsemedov/transactions?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import polars as pl\n",
    "import time\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to measure and log results\n",
    "benchmark_results = []\n",
    "\n",
    "def measure_and_log(step_name, library_name, operation_func, *args, **kwargs):\n",
    "    tracemalloc.start()\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    result = operation_func(*args, **kwargs)\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    _, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    # Build the new entry\n",
    "    new_entry = {\n",
    "        \"Library\": library_name,\n",
    "        \"Step\": step_name,\n",
    "        \"Time (s)\": round(end - start, 4),\n",
    "        \"Peak Memory (MB)\": round(peak / 10**6, 4)\n",
    "    }\n",
    "\n",
    "    # Remove existing entry for same library + step\n",
    "    global benchmark_results\n",
    "    benchmark_results = [\n",
    "        entry for entry in benchmark_results\n",
    "        if not (entry[\"Library\"] == library_name and entry[\"Step\"] == step_name)\n",
    "    ]\n",
    "\n",
    "    # Add the new one\n",
    "    benchmark_results.append(new_entry)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_csv = '/Users/adolfomytr/Documents/Data Science/Polars/synthetic_fraud_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv():\n",
    "    return pl.read_csv(transactions_csv, try_parse_dates=True)\n",
    "\n",
    "df = measure_and_log(\"Load CSV\", \"Polars Eager\", load_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric columns\n",
    "summary = measure_and_log(\n",
    "    \"Describe numeric columns\", \"Polars Eager\",\n",
    "    lambda: df.describe()\n",
    ")\n",
    "\n",
    "# Value counts for merchant_type\n",
    "merchant_type_counts = measure_and_log(\n",
    "    \"Merchant type value counts\", \"Polars Eager\",\n",
    "    lambda: df.select(pl.col(\"merchant_type\")).to_series().value_counts()\n",
    ")\n",
    "\n",
    "# Missing values per column\n",
    "missing_values = measure_and_log(\n",
    "    \"Missing values per column\", \"Polars Eager\",\n",
    "    lambda: df.null_count()\n",
    ")\n",
    "\n",
    "# Minimum timestamp\n",
    "min_date = measure_and_log(\n",
    "    \"Min txn_date\", \"Polars Eager\",\n",
    "    lambda: df.select(pl.col(\"timestamp\").min())\n",
    ")\n",
    "\n",
    "# Maximum timestamp\n",
    "max_date = measure_and_log(\n",
    "    \"Max txn_date\", \"Polars Eager\",\n",
    "    lambda: df.select(pl.col(\"timestamp\").max())\n",
    ")\n",
    "\n",
    "# Unique customer_id count\n",
    "unique_customers = measure_and_log(\n",
    "    \"Unique customer_id count\", \"Polars Eager\",\n",
    "    lambda: df.select(pl.col(\"customer_id\")).n_unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Transaction Volume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily transaction count\n",
    "daily_txns = measure_and_log(\"Daily transaction count\", \"Polars Eager\", lambda: \n",
    "    df.group_by(\"timestamp\").len()\n",
    ")\n",
    "\n",
    "# Monthly transaction count (convert timestamp to month)\n",
    "monthly_txns = measure_and_log(\"Monthly transaction count\", \"Polars Eager\", lambda: \n",
    "    df.with_columns(\n",
    "        pl.col(\"timestamp\").dt.truncate(\"1mo\").alias(\"month\")\n",
    "    ).group_by(\"month\").len()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Transaction Amount Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average and total transaction amount by type\n",
    "avg_total_by_type = measure_and_log(\"Avg/Total txn by merch type\", \"Polars Eager\", lambda: \n",
    "    df.group_by(\"merchant_type\").agg([\n",
    "        pl.col(\"amount\").mean().alias(\"avg_amount\"),\n",
    "        pl.col(\"amount\").sum().alias(\"total_amount\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Top 10 customers by transaction volume\n",
    "top_customers = measure_and_log(\"Top 10 customers by volume\", \"Polars Eager\", lambda: \n",
    "    df.group_by(\"customer_id\").agg(\n",
    "        pl.col(\"amount\").sum().alias(\"total_amount\")\n",
    "    ).sort(\"total_amount\", descending=True).head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Fraud Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud vs non-fraud count\n",
    "fraud_vs_nonfraud = measure_and_log(\"Fraud vs Non-Fraud Count\", \"Polars Eager\", lambda: \n",
    "    df.select(pl.col(\"is_fraud\")).to_series().value_counts()\n",
    ")\n",
    "\n",
    "# Fraud rate by transaction type\n",
    "fraud_rate_by_type = measure_and_log(\"Fraud rate by merchant_type\", \"Polars Eager\", lambda: \n",
    "    df.group_by(\"merchant_type\").agg(\n",
    "        pl.col(\"is_fraud\").mean().alias(\"fraud_rate\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Stats for fraudulent transaction amounts\n",
    "fraud_amount_distribution = measure_and_log(\"Fraud amount stats\", \"Polars Eager\", lambda: \n",
    "    df.filter(pl.col(\"is_fraud\") == 1).select(\"amount\").describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Export benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (14, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Library</th><th>Step</th><th>Time (s)</th><th>Peak Memory (MB)</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Load CSV&quot;</td><td>11.0512</td><td>0.5682</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Describe numeric columns&quot;</td><td>1.371</td><td>0.292</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Merchant type value counts&quot;</td><td>0.2783</td><td>0.0121</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Missing values per column&quot;</td><td>0.0002</td><td>0.001</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Min txn_date&quot;</td><td>0.0213</td><td>0.002</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Avg/Total txn by merch type&quot;</td><td>0.3571</td><td>0.0038</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Top 10 customers by volume&quot;</td><td>7.7584</td><td>0.0029</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Fraud vs Non-Fraud Count&quot;</td><td>0.1283</td><td>0.0027</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Fraud rate by merchant_type&quot;</td><td>0.1447</td><td>0.0028</td></tr><tr><td>&quot;Polars Eager&quot;</td><td>&quot;Fraud amount stats&quot;</td><td>0.285</td><td>0.0139</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (14, 4)\n",
       "┌──────────────┬─────────────────────────────┬──────────┬──────────────────┐\n",
       "│ Library      ┆ Step                        ┆ Time (s) ┆ Peak Memory (MB) │\n",
       "│ ---          ┆ ---                         ┆ ---      ┆ ---              │\n",
       "│ str          ┆ str                         ┆ f64      ┆ f64              │\n",
       "╞══════════════╪═════════════════════════════╪══════════╪══════════════════╡\n",
       "│ Polars Eager ┆ Load CSV                    ┆ 11.0512  ┆ 0.5682           │\n",
       "│ Polars Eager ┆ Describe numeric columns    ┆ 1.371    ┆ 0.292            │\n",
       "│ Polars Eager ┆ Merchant type value counts  ┆ 0.2783   ┆ 0.0121           │\n",
       "│ Polars Eager ┆ Missing values per column   ┆ 0.0002   ┆ 0.001            │\n",
       "│ Polars Eager ┆ Min txn_date                ┆ 0.0213   ┆ 0.002            │\n",
       "│ …            ┆ …                           ┆ …        ┆ …                │\n",
       "│ Polars Eager ┆ Avg/Total txn by merch type ┆ 0.3571   ┆ 0.0038           │\n",
       "│ Polars Eager ┆ Top 10 customers by volume  ┆ 7.7584   ┆ 0.0029           │\n",
       "│ Polars Eager ┆ Fraud vs Non-Fraud Count    ┆ 0.1283   ┆ 0.0027           │\n",
       "│ Polars Eager ┆ Fraud rate by merchant_type ┆ 0.1447   ┆ 0.0028           │\n",
       "│ Polars Eager ┆ Fraud amount stats          ┆ 0.285    ┆ 0.0139           │\n",
       "└──────────────┴─────────────────────────────┴──────────┴──────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.DataFrame(benchmark_results).write_csv(\"/Users/adolfomytr/Documents/Data Science/Polars/pandas-vs-polars/benchmark_results/benchmark_polars_eager.csv\")\n",
    "pl.DataFrame(benchmark_results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd298f439cec3fce4824eab919085afc570f8b01b13c0e9ab505c6bd85a627bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
